{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3f666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_hieararchical_form(features):\n",
    "    if lang == \"pol\":\n",
    "        features = features.split(\";\")\n",
    "        word_class = features[0]\n",
    "        if (word_class==\"V\"):\n",
    "            for i in range (len(features)):                \n",
    "                if features[i].isnumeric() or features[i]==\"SG\" or features[i]==\"PL\":\n",
    "                    # SG;1 -> 1;SG\n",
    "                    if features[i+1].isnumeric():\n",
    "                        tmp = features[i+1]\n",
    "                        features[i+1] = features[i]\n",
    "                        features[i] = tmp\n",
    "                    # V;...;1;SG -> ...;NOM(1,SG)\n",
    "                    hierarchical = \"NOM(\"+\",\".join(features[i:])+\")\"\n",
    "                    result = \";\".join(features[:i] + [hierarchical])\n",
    "                    print(result)\n",
    "                    return result\n",
    "        elif (word_class==\"N\" or word_class==\"ADJ\"):\n",
    "            for i in range (len(features)):\n",
    "                if features[i]==\"SG\" or features[i]==\"PL\":\n",
    "                    hierarchical = \"(\"+\",\".join(features[i:])+\")\"\n",
    "                    result = \";\".join(features[:i]) + hierarchical\n",
    "                    print(result)\n",
    "                    return result\n",
    "        else:\n",
    "            exit(\"invalid word class: \" + word_class)\n",
    "    elif lang == \"ote\":\n",
    "        if features[0]==\"V\":\n",
    "            for i in range (len(features)):\n",
    "                if features[i]==\"SG\" or features[i].isnumeric():\n",
    "                    hierarchical = \"NOM(\"+\",\".join(features[i:])+\")\"\n",
    "                    return \";\".join(features[:i] + [hierarchical])\n",
    "        else: exit(\"invalid word class: \",word_class)\n",
    "    else: exit(\"invalid language: \" + lang)\n",
    "\n",
    "\n",
    "def preprocess(x):\n",
    "    x = x.strip()\n",
    "    lemma, target, features = x.split(\"\\t\")\n",
    "    processed_features = to_hierarchical_form(features)\n",
    "    line = lemma + \"\\t\" + processed_features + \"\\t\" + target\n",
    "    return line\n",
    "\n",
    "path_data = \"../data/\"\n",
    "LANGS = [\"ote\",\"pol\"]\n",
    "for lang in LANGS:\n",
    "    with open (path + lang,\"r\") as data_file, open (path + lang + \".args\",\"w\") as output_file:\n",
    "        data_lines = data_file.readlines()\n",
    "        output_file.write(\"\\n\".join(map(preprocess,data_lines)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804e3956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split and sample from the paradigms according to the SIGMORPHONâ€“UniMorph 2023 Shared Task 0 Paper\n",
    "def get_lemma(line):\n",
    "    lemma = line.split(\"\\t\")[0]\n",
    "    return lemma\n",
    "\n",
    "from random import sample,shuffle\n",
    "from math import floor\n",
    "from itertools import groupby\n",
    "path_data = \"../data/\"\n",
    "LANGS = [\"ote\",\"pol\"]\n",
    "\n",
    "for lang in LANGS:\n",
    "    with open (path_data + lang,\"r\") as data_file, open (path_data + lang + \".trn\",\"w\") as train_file, open (path_data + lang + \".dev\",\"w\") as dev_file,open (path_data + lang + \".tst\",\"w\") as test_file:\n",
    "        data_lines = [line.strip() for line in data_file.readlines()]\n",
    "        tables = [(k, list(g)) for k, g in groupby(data_lines, get_lemma)]   \n",
    "        \n",
    "        sampled_tables = sample(tables,500)\n",
    "        size = len(sampled_tables)\n",
    "        datasets = [ sampled_tables[:floor(0.8*size)], sampled_tables[floor(0.8*size):floor(0.9*size)], sampled_tables[floor(0.9*size):] ]\n",
    "\n",
    "        train_forms = [form for lemma,table in datasets[0] for form in table]\n",
    "        dev_forms = [form for lemma,table in datasets[1] for form in table]\n",
    "        test_forms = [form for lemma,table in datasets[2] for form in table]\n",
    "        \n",
    "        if len(dev_forms) < 1000 or len(test_forms) < 1000 or len(train_forms) < 10000:\n",
    "            exit(\"more tables needed for lang: \" + lang)\n",
    "            \n",
    "        # sampling and retaining order of the forms\n",
    "        indices_train = sorted(sample(range(len(train_forms)), 10000))\n",
    "        indices_dev =  sorted(sample(range(len(dev_forms)), 1000))\n",
    "        indices_test = sorted( sample(range(len(test_forms)), 1000))\n",
    "\n",
    "        train_samples = [train_forms[i] for i in indices_train]\n",
    "        dev_samples = [dev_forms[i] for i in indices_dev]\n",
    "        test_samples = [test_forms[i] for i in indices_test]\n",
    "\n",
    "        train_txt = \"\\n\".join(train_samples) \n",
    "        dev_txt = \"\\n\".join(dev_samples) \n",
    "        test_txt = \"\\n\".join(test_samples) \n",
    "\n",
    "        train_file.write(train_txt)\n",
    "        dev_file.write(dev_txt)\n",
    "        test_file.write(test_txt)\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
