{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d573e25",
   "metadata": {},
   "source": [
    "# Combine languages with *language code* or language word and convert to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01ca5330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/\n",
      "<_io.TextIOWrapper name='data/grc-language-code_trn.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/grc-language-code_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/grc-language-code_dev.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/grc-language-word_trn.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/grc-language-word_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/grc-language-word_dev.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/dan-language-code_trn.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/dan-language-code_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/dan-language-code_dev.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/dan-language-word_trn.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/dan-language-word_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/dan-language-word_dev.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/fra-language-code_trn.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/fra-language-code_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/fra-language-code_dev.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/fra-language-word_trn.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/fra-language-word_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/fra-language-word_dev.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/sme-language-code_trn.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/sme-language-code_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/sme-language-code_dev.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/sme-language-word_trn.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/sme-language-word_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/sme-language-word_dev.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/deu-language-code_trn.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/deu-language-code_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/deu-language-code_dev.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/deu-language-word_trn.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/deu-language-word_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/deu-language-word_dev.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/nav-language-code_trn.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/nav-language-code_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/nav-language-code_dev.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/nav-language-word_trn.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/nav-language-word_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/nav-language-word_dev.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/jap-language-code_trn.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/jap-language-code_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/jap-language-code_dev.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/jap-language-word_trn.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/jap-language-word_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/jap-language-word_dev.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/klr-language-code_trn.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/klr-language-code_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/klr-language-code_dev.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/klr-language-word_trn.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/klr-language-word_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/klr-language-word_dev.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/eng-language-code_trn.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/eng-language-code_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/eng-language-code_dev.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/eng-language-word_trn.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/eng-language-word_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/eng-language-word_dev.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/ote-language-code_trn.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/ote-language-code_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/ote-language-code_dev.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/ote-language-word_trn.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/ote-language-word_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/ote-language-word_dev.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/pol-language-code_trn.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/pol-language-code_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/pol-language-code_dev.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/pol-language-word_trn.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/pol-language-word_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/pol-language-word_dev.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/amh-language-code_trn.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/amh-language-code_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/amh-language-code_dev.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/amh-language-word_trn.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/amh-language-word_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/amh-language-word_dev.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/csb-language-code_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/csb-language-word_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/mul-language-code_trn.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/mul-language-code_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/mul-language-code_dev.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/mul-language-word_trn.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/mul-language-word_tst.json' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='data/mul-language-word_dev.json' mode='w' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../../2023InflectionST/part1/data/\"\n",
    "OUT_DIR = \"data/\"\n",
    "# LANGS = [\"deu\",\"eng\"]\n",
    "# TARGET_LANG = \"deu_eng\"\n",
    "# LANGS = [\"grc\",\"dan\",\"fra\",\"sme\",\"deu\",\"nav\",\"jap\",\"klr\",\"eng\"]\n",
    "# TARGET_LANG = \"mul\"\n",
    "LANGS_UNIQUE = [\"grc\",\"dan\",\"fra\",\"sme\",\"deu\",\"nav\",\"jap\",\"klr\",\"eng\"]+[\"ote\",\"pol\",\"amh\",\"csb\"]\n",
    "#TARGET_LANG = \"mul_2\"\n",
    "LANG_WORD_OF_CODE = {\"grc\":\"Ancient Greek\",\n",
    "                  \"dan\": \"Danish\",\n",
    "                  \"fra\":\"French\",\n",
    "                  \"sme\":\"SÃ¡mi\",\n",
    "                  \"deu\":\"German\",\n",
    "                  \"nav\":\"Navajo\",\n",
    "                  \"jap\":\"Japanese\",\n",
    "                  \"klr\":\"Khaling\",\n",
    "                  \"eng\":\"English\",\n",
    "                  \"ote\":\"Mezquital Otomi\",\n",
    "                  \"pol\":\"Polish\",\n",
    "                  \"amh\":\"Amharic\",\n",
    "                  \"csb\":\"Kashubian\"}\n",
    "\n",
    "TARGET_LANGS = [\"grc\",\"dan\",\"fra\",\"sme\",\"deu\",\"nav\",\"jap\",\"klr\",\"eng\",\"ote\",\"pol\",\"amh\",\"csb\",\"mul\"]\n",
    "DATASET_COMPLETE = [\"trn\",\"tst\",\"dev\"]\n",
    "LANGUAGE_CODES = [True,False]\n",
    "print(OUT_DIR)\n",
    "for target_lang in TARGET_LANGS:\n",
    "    target_lang_initials = target_lang\n",
    "    for lang_code in LANGUAGE_CODES:\n",
    "        if lang_code: \n",
    "            target_lang = target_lang_initials  + \"-language-code\"\n",
    "        else: \n",
    "            target_lang = target_lang_initials  + \"-language-word\"\n",
    "            \n",
    "        for dataset in DATASET_COMPLETE:\n",
    "            if dataset != \"tst\" and  \"csb\" in target_lang: continue # csb only as test data\n",
    "                \n",
    "            OUT=OUT_DIR + target_lang  + \"_\" + dataset + \".json\"\n",
    "            with open (OUT,\"w\") as out_file:\n",
    "                print(out_file)\n",
    "                if target_lang in [\"mul-language-code\",\"mul-language-word\"]: LANGS = LANGS_UNIQUE\n",
    "                else: LANGS = [target_lang_initials]\n",
    "                for lang in LANGS:\n",
    "                    if dataset != \"tst\" and lang == \"csb\": continue # csb only as test data\n",
    "                        \n",
    "                    with open(DATA_PATH + lang + \".\" + dataset,\"r\") as in_file:\n",
    "                        for line in in_file:\n",
    "                            line = line.strip()\n",
    "                            lemma, features, target = line.split(\"\\t\")\n",
    "                            if lang_code: context = lang + \": \"\n",
    "                            else: context = LANG_WORD_OF_CODE[lang]+ \": \"\n",
    "                            json_line = f'{{\"input\": \"{context}Inflect {lemma} | {features}\",\"target\": \"{target}\"}}'\n",
    "                            out_file.write(json_line + \"\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
